#!/usr/bin/env python3

import csv
import io
import json
import os

import requests

HERE = os.path.abspath(os.path.dirname(__file__))
ROOT = os.path.dirname(HERE)
PUBLIC = os.path.join(ROOT, "public")
METADATA_NAME = "metadata.json"
THUMBNAIL_PREFIX = "https://drive.google.com/thumbnail?id="
IMAGE_PREFIX = "https://drive.google.com/uc?export=view&id="
URL_PREFIX = "https://docs.google.com/document/u/0/export?format=txt&id={}"


def find_page_urls(pages):
    if not pages:
        path = os.path.join(ROOT, ".env.local")
        with open(path) as f:
            line = [line.strip() for line in f if line.startswith(f"PAGES")][-1]
            pages = line.split("=", 1)[-1].strip().strip('"')
    return [page.split(":") for page in pages.split(";")] if pages else []


def download_page(download_dir, path, doc_id):
    full_path = os.path.join(download_dir, path)
    page_url = URL_PREFIX.format(doc_id)
    text = requests.get(page_url).text
    with open(full_path, "w") as f:
        f.write(text)

    return full_path


def download_pages(pages, parent_dir):
    for path, doc_id in find_page_urls(pages):
        download_page(parent_dir, path, doc_id)


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument("-p", "--pages", default="")
    parser.add_argument("-d", "--download-dir", default="public")

    args = parser.parse_args()
    download_pages(args.pages, args.download_dir)
